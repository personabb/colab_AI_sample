{"cells":[{"cell_type":"markdown","metadata":{"id":"0FaGsjMEAD_2"},"source":["# SBV2学習データ準備用のGoogle Colabスクリプト\n","公式の下記の実装を使わせていただいております。\n","\n","https://github.com/litagin02/Style-Bert-VITS2/blob/master/colab.ipynb\n","\n","「ランタイム」→「ランタイムのタイプを変更」\n","\n","から、「T4 GPU」に変更してから、「Shift+Enter」で上からセルを実行してください。"]},{"cell_type":"markdown","metadata":{"id":"lmd3dNUOAJx0"},"source":["# Google Driveのマウント\n","認証が入るので、最初のセルに置くのをオススメします。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24460,"status":"ok","timestamp":1732842454606,"user":{"displayName":"akc kug","userId":"06740133965745108662"},"user_tz":-540},"id":"WmxWQzf17dI7","outputId":"c5ba0e5e-2ae0-484c-a38e-e8f47261dfc2"},"outputs":[],"source":["#Google Driveのフォルダをマウント（認証入る）\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"IOOAaHR4AMPf"},"source":["# 必要パッケージのインストール"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":67528,"status":"ok","timestamp":1732842522131,"user":{"displayName":"akc kug","userId":"06740133965745108662"},"user_tz":-540},"id":"nm-RXID9GzAV","outputId":"62bf24fe-6f00-48ae-e7e3-e4cd4f69f154"},"outputs":[],"source":["# このセルを実行して環境構築してください。\n","# エラーダイアログ「WARNING: The following packages were previously imported in this runtime: [pydevd_plugins]」が出るが「キャンセル」を選択して続行してください。\n","\n","import os\n","\n","os.environ[\"PATH\"] += \":/root/.cargo/bin\"\n","\n","!curl -LsSf https://astral.sh/uv/install.sh | sh\n","!git clone https://github.com/litagin02/Style-Bert-VITS2.git\n","%cd Style-Bert-VITS2/\n","!uv pip install --system -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"zPKbiuu1AWT8"},"source":["# 各種パスやモデル名の指定"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33854,"status":"ok","timestamp":1732842555984,"user":{"displayName":"akc kug","userId":"06740133965745108662"},"user_tz":-540},"id":"Y-tV-unf8PoG","outputId":"c655453b-8f94-418e-850e-27a8fba56b7a"},"outputs":[],"source":["model_name = \"amitaro\"\n","\n","# Google Driveでのパスを特定する\n","import glob\n","import os\n","drive_path = os.path.dirname(glob.glob('/content/drive/MyDrive/**/colab_SBV2train_sample/SBV2-prepare.ipynb', recursive=True)[0])\n","print(drive_path)\n","\n","# 学習に必要なファイルや途中経過が保存されるディレクトリ\n","dataset_root = f\"{drive_path}/Data\"\n","\n","# 学習結果（音声合成に必要なファイルたち）が保存されるディレクトリ\n","assets_root = f\"{drive_path}/model_assets\"\n","\n","import yaml\n","with open(\"configs/paths.yml\", \"w\", encoding=\"utf-8\") as f:\n","    yaml.dump({\"dataset_root\": dataset_root, \"assets_root\": assets_root}, f)"]},{"cell_type":"markdown","metadata":{"id":"xFP50pmbAyFG"},"source":["# 音声ファイルを学習可能な適切な長さに分割するスクリプト\n","\n","本家のスクリプトでは、大きな動画データを複数処理する際に、無料版のColabではRAMオーバーをしてしまうため、処理時間を少し犠牲にする代わりに、無料のColabでも動作できるスクリプトを実装します"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"huKmNi_bB6LY"},"outputs":[],"source":["\n","#無料版のRAM12.7GBしかないColabでも実行可能な「slice.py」を実装\n","\n","py_slice = \"\"\"\n","import argparse\n","import shutil\n","from pathlib import Path\n","from queue import Queue\n","from threading import Thread\n","from typing import Any, Optional\n","import gc\n","\n","import soundfile as sf\n","import torch\n","from tqdm import tqdm\n","\n","from config import get_path_config\n","from style_bert_vits2.logging import logger\n","from style_bert_vits2.utils.stdout_wrapper import SAFE_STDOUT\n","\n","\n","def is_audio_file(file: Path) -> bool:\n","    supported_extensions = [\".wav\", \".flac\", \".mp3\", \".ogg\", \".opus\", \".m4a\"]\n","    return file.suffix.lower() in supported_extensions\n","\n","\n","def get_stamps(\n","    vad_model: Any,\n","    utils: Any,\n","    audio_file: Path,\n","    min_silence_dur_ms: int = 700,\n","    min_sec: float = 2,\n","    max_sec: float = 12,\n","):\n","    (get_speech_timestamps, _, read_audio, *_) = utils\n","    sampling_rate = 16000  # 16kHzか8kHzのみ対応\n","\n","    min_ms = int(min_sec * 1000)\n","\n","    wav = read_audio(str(audio_file), sampling_rate=sampling_rate)\n","    speech_timestamps = get_speech_timestamps(\n","        wav,\n","        vad_model,\n","        sampling_rate=sampling_rate,\n","        min_silence_duration_ms=min_silence_dur_ms,\n","        min_speech_duration_ms=min_ms,\n","        max_speech_duration_s=max_sec,\n","    )\n","\n","    return speech_timestamps\n","\n","\n","def split_wav(\n","    vad_model: Any,\n","    utils: Any,\n","    audio_file: Path,\n","    target_dir: Path,\n","    min_sec: float = 2,\n","    max_sec: float = 12,\n","    min_silence_dur_ms: int = 700,\n","    time_suffix: bool = False,\n",") -> tuple[float, int]:\n","    margin: int = 200  # ミリ秒単位で、音声の前後に余裕を持たせる\n","    speech_timestamps = get_stamps(\n","        vad_model=vad_model,\n","        utils=utils,\n","        audio_file=audio_file,\n","        min_silence_dur_ms=min_silence_dur_ms,\n","        min_sec=min_sec,\n","        max_sec=max_sec,\n","    )\n","\n","    data, sr = sf.read(audio_file)\n","\n","    total_ms = len(data) / sr * 1000\n","\n","    file_name = audio_file.stem\n","    target_dir.mkdir(parents=True, exist_ok=True)\n","\n","    total_time_ms: float = 0\n","    count = 0\n","\n","    # タイムスタンプに従って分割し、ファイルに保存\n","    for i, ts in enumerate(speech_timestamps):\n","        start_ms = max(ts[\"start\"] / 16 - margin, 0)\n","        end_ms = min(ts[\"end\"] / 16 + margin, total_ms)\n","\n","        start_sample = int(start_ms / 1000 * sr)\n","        end_sample = int(end_ms / 1000 * sr)\n","        segment = data[start_sample:end_sample]\n","\n","        if time_suffix:\n","            file = f\"{file_name}-{int(start_ms)}-{int(end_ms)}.wav\"\n","        else:\n","            file = f\"{file_name}-{i}.wav\"\n","        sf.write(str(target_dir / file), segment, sr)\n","        total_time_ms += end_ms - start_ms\n","        count += 1\n","\n","    # メモリを解放\n","    del data\n","    gc.collect()\n","\n","    return total_time_ms / 1000, count\n","\n","\n","if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--min_sec\", \"-m\", type=float, default=2, help=\"Minimum seconds of a slice\")\n","    parser.add_argument(\"--max_sec\", \"-M\", type=float, default=12, help=\"Maximum seconds of a slice\")\n","    parser.add_argument(\"--input_dir\", \"-i\", type=str, default=\"inputs\", help=\"Directory of input wav files\")\n","    parser.add_argument(\"--model_name\", type=str, required=True, help=\"Output will be in Data/{model_name}/raw/\")\n","    parser.add_argument(\"--min_silence_dur_ms\", \"-s\", type=int, default=700, help=\"Silence above this duration (ms)\")\n","    parser.add_argument(\"--time_suffix\", \"-t\", action=\"store_true\", help=\"Add time suffix to output file names\")\n","    parser.add_argument(\"--num_processes\", type=int, default=3, help=\"Number of parallel processes. Default is 3.\")\n","    args = parser.parse_args()\n","\n","    path_config = get_path_config()\n","    dataset_root = path_config.dataset_root\n","\n","    model_name = str(args.model_name)\n","    input_dir = Path(args.input_dir)\n","    output_dir = dataset_root / model_name / \"raw\"\n","    min_sec: float = args.min_sec\n","    max_sec: float = args.max_sec\n","    min_silence_dur_ms: int = args.min_silence_dur_ms\n","    time_suffix: bool = args.time_suffix\n","    num_processes: int = args.num_processes\n","\n","    audio_files = [file for file in input_dir.rglob(\"*\") if is_audio_file(file)]\n","\n","    logger.info(f\"Found {len(audio_files)} audio files.\")\n","    if output_dir.exists():\n","        logger.warning(f\"Output directory {output_dir} already exists, deleting...\")\n","        shutil.rmtree(output_dir)\n","\n","    # バッチサイズの設定\n","    batch_size = 1  # 一度に処理するファイル数\n","    from math import ceil\n","    num_batches = ceil(len(audio_files) / batch_size)\n","\n","    # モデルをダウンロード\n","    _ = torch.hub.load(\n","        repo_or_dir=\"litagin02/silero-vad\",\n","        model=\"silero_vad\",\n","        onnx=True,\n","        trust_repo=True,\n","    )\n","\n","    # 並列処理の準備\n","    def process_queue(\n","        q: Queue[Optional[Path]],\n","        result_queue: Queue[tuple[float, int]],\n","        error_queue: Queue[tuple[Path, Exception]],\n","    ):\n","        vad_model, utils = torch.hub.load(\n","            repo_or_dir=\"litagin02/silero-vad\",\n","            model=\"silero_vad\",\n","            onnx=True,\n","            trust_repo=True,\n","        )\n","        while True:\n","            file = q.get()\n","            if file is None:\n","                q.task_done()\n","                break\n","            try:\n","                rel_path = file.relative_to(input_dir)\n","                time_sec, count = split_wav(\n","                    vad_model=vad_model,\n","                    utils=utils,\n","                    audio_file=file,\n","                    target_dir=output_dir / rel_path.parent,\n","                    min_sec=min_sec,\n","                    max_sec=max_sec,\n","                    min_silence_dur_ms=min_silence_dur_ms,\n","                    time_suffix=time_suffix,\n","                )\n","                result_queue.put((time_sec, count))\n","            except Exception as e:\n","                logger.error(f\"Error processing {file}: {e}\")\n","                error_queue.put((file, e))\n","                result_queue.put((0, 0))\n","            finally:\n","                q.task_done()\n","\n","    for batch_idx in range(num_batches):\n","        start_idx = batch_idx * batch_size\n","        end_idx = min((batch_idx + 1) * batch_size, len(audio_files))\n","        batch_files = audio_files[start_idx:end_idx]\n","\n","        q: Queue[Optional[Path]] = Queue()\n","        result_queue: Queue[tuple[float, int]] = Queue()\n","        error_queue: Queue[tuple[Path, Exception]] = Queue()\n","\n","        threads = [\n","            Thread(target=process_queue, args=(q, result_queue, error_queue))\n","            for _ in range(min(num_processes, len(batch_files)))\n","        ]\n","\n","        for t in threads:\n","            t.start()\n","\n","        pbar = tqdm(total=len(batch_files), file=SAFE_STDOUT)\n","        for file in batch_files:\n","            q.put(file)\n","\n","        # 結果の集計\n","        total_sec = 0\n","        total_count = 0\n","        for _ in range(len(batch_files)):\n","            time, count = result_queue.get()\n","            total_sec += time\n","            total_count += count\n","            pbar.update(1)\n","\n","        q.join()\n","\n","        for _ in range(len(threads)):\n","            q.put(None)\n","\n","        for t in threads:\n","            t.join()\n","\n","        pbar.close()\n","\n","    if not error_queue.empty():\n","        error_str = \"Error slicing some files:\"\n","        while not error_queue.empty():\n","            file, e = error_queue.get()\n","            error_str += f\"{file}: {e}\"\n","        raise RuntimeError(error_str)\n","\n","    logger.info(f\"Slice done! Total time: {total_sec / 60:.2f} min, {total_count} files.\")\n","\n","\"\"\"\n","\n","with open(\"./slice.py\", \"w\") as f:\n","    f.write(py_slice)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":390359,"status":"ok","timestamp":1732842129739,"user":{"displayName":"akc kug","userId":"06740133965745108662"},"user_tz":-540},"id":"Z7gjw7U9_a_f","outputId":"d3820254-a7a2-4ca8-e30d-96941d2ac779"},"outputs":[],"source":["# 元となる音声ファイル（wav形式）を入れるディレクトリ\n","input_dir = f\"{drive_path}/inputs\"\n","\n","!python slice.py -i {input_dir} --model_name {model_name}\n"]},{"cell_type":"markdown","metadata":{"id":"UeImZEwdCUQa"},"source":["# 分割した音声ファイルに対して、音声認識モデルWhisperによる文字起こしを実施するスクリプト\n","\n","より学習の品質を上げたい場合は、自動的に行なった文字起こしの後に、自分で音声を確認しながら、`Data/{model_name}/esd.list`の文字起こしを修正することをおすすめします。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":1921983,"status":"ok","timestamp":1732844479107,"user":{"displayName":"akc kug","userId":"06740133965745108662"},"user_tz":-540},"id":"6TD7Vo3EWatd","outputId":"48c45c9b-3eac-423c-a7f3-c00e406d429b"},"outputs":[],"source":["# こういうふうに書き起こして欲しいという例文（句読点の入れ方・笑い方や固有名詞等）\n","initial_prompt = \"こんにちは。元気、ですかー？ふふっ、私は……ちゃんと元気だよ！\"\n","\n","!python transcribe.py --model_name {model_name} --initial_prompt {initial_prompt} --use_hf_whisper"]},{"cell_type":"markdown","metadata":{"id":"DI5sW4FEJKjh"},"source":["# 実行後Colabノードブックのランタイムを削除する\n","\n","特に、有料版のColabでは、接続時間に応じてコンピューティングユニットが消費されてしまうので、節約のため、学習完了したら即座にColabのランタイムを削除する必要がある。\n","\n","下記セルにおいて、`FLAG = True`として、実行すると、ランタイムが接続解除される"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aW320UfE-NQo"},"outputs":[],"source":["# ノートブックの解放\n","FLAG = False\n","\n","from google.colab import runtime\n","\n","if FLAG:\n","    runtime.unassign()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
