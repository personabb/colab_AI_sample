{"cells":[{"cell_type":"markdown","metadata":{"id":"R12512yzUsxH"},"source":["# Google Colabにて必要なモジュールを取得"]},{"cell_type":"code","execution_count":1,"metadata":{"collapsed":true,"id":"N2N8QRtXD1bS"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/tensorboardX-2.6.2.2-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/six-1.16.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/cycler-0.12.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/xmltodict-0.13.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/MarkupSafe-2.1.5-py3.11-macosx-14.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/kiwisolver-1.4.5-py3.11-macosx-14.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/PySocks-1.7.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/audioread-3.0.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/decorator-5.1.1-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/kaldiio-2.18.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/soundfile-0.12.1-py3.11-macosx-14.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/mpmath-1.3.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mDEPRECATION: Loading egg at /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/charset_normalizer-3.3.2-py3.11-macosx-14.5-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: langgraph in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (0.2.46)\n","Requirement already satisfied: langchain_openai in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (0.1.10)\n","Requirement already satisfied: langchain_core in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (0.2.43)\n","Requirement already satisfied: httpx in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (0.27.0)\n","Requirement already satisfied: requests in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (2.31.0)\n","Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.0 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langgraph) (2.0.3)\n","Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.32 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langgraph) (0.1.35)\n","Requirement already satisfied: openai<2.0.0,>=1.26.0 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langchain_openai) (1.46.0)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langchain_openai) (0.7.0)\n","Requirement already satisfied: PyYAML>=5.3 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langchain_core) (6.0.1)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langchain_core) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langchain_core) (0.1.142)\n","Requirement already satisfied: packaging<25,>=23.2 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langchain_core) (23.2)\n","Requirement already satisfied: pydantic<3,>=1 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langchain_core) (2.6.1)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langchain_core) (8.4.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langchain_core) (4.12.2)\n","Requirement already satisfied: anyio in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from httpx) (4.2.0)\n","Requirement already satisfied: certifi in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from httpx) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from httpx) (1.0.2)\n","Requirement already satisfied: idna in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from httpx) (3.6)\n","Requirement already satisfied: sniffio in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from httpx) (1.3.0)\n","Requirement already satisfied: h11<0.15,>=0.13 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from httpcore==1.*->httpx) (0.14.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages/charset_normalizer-3.3.2-py3.11-macosx-14.5-arm64.egg (from requests) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from requests) (2.2.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.0->langgraph) (1.1.0)\n","Requirement already satisfied: httpx-sse>=0.4.0 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.4.0)\n","Requirement already satisfied: orjson>=3.10.1 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10.5)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.112->langchain_core) (1.0.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.9.0)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (0.5.0)\n","Requirement already satisfied: tqdm>4 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.66.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from pydantic<3,>=1->langchain_core) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.2 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from pydantic<3,>=1->langchain_core) (2.16.2)\n","Requirement already satisfied: regex>=2022.1.18 in /Users/kunieda/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install langgraph langchain_openai langchain_core httpx requests"]},{"cell_type":"markdown","metadata":{"id":"yl78UxwAUsxN"},"source":["# LangChainで利用するLLMの設定"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":12798,"status":"ok","timestamp":1731687811284,"user":{"displayName":"akc kug","userId":"06740133965745108662"},"user_tz":-540},"id":"NWDUAG5BD4nE"},"outputs":[],"source":["import os\n","from langchain_openai import AzureChatOpenAI\n","\n","# 非推奨だが環境変数をベタがきしても良い\n","#os.environ[\"OPENAI_API_VERSION\"] = \"2024-xx-xx-preview\"\n","#os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://xxxxxxxxxx.openai.azure.com\"\n","#os.environ[\"AZURE_OPENAI_API_KEY\"] = \"xxxxxxxxxx\"\n","\n","# Google Colabで設定した場合\n","from google.colab import userdata\n","os.environ[\"OPENAI_API_VERSION\"] = userdata.get(\"OPENAI_API_VERSION\")\n","os.environ[\"AZURE_OPENAI_ENDPOINT\"] = userdata.get(\"AZURE_OPENAI_ENDPOINT\")\n","os.environ[\"AZURE_OPENAI_API_KEY\"] = userdata.get(\"AZURE_OPENAI_API_KEY\")\n","\n","\n","model = AzureChatOpenAI(\n","    azure_deployment=\"gpt-4o\",\n","    temperature=0,\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"BZexbBdJUsxO"},"source":["# LangChain単体で利用して（Chainを使わずに）、簡単な小説を作成するコード"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"auLbZS-lcwXs"},"outputs":[],"source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","user_input = \"ハッピーエンドのボーイミーツガール\"\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",\"ユーザが指定するジャンル等の情報をもとに、短編小説を生成するAIです。\"),\n","        (\"human\", \"{user_input}\")\n","    ]\n",")\n","\n","output_parser = StrOutputParser()\n","\n","#LCELを使わない場合\n","prompt_value = prompt.invoke({\"user_input\": user_input})\n","ai_message = model.invoke(prompt_value)\n","output = output_parser.invoke(ai_message)\n","\n","print(prompt_value)\n","print(ai_message)\n","print(output)\n","\n","#テキストファイルに出力。Colabの場合は、Colabのフォルダからダウンロードする\n","with open(\"output_sample01.txt\", \"w\") as f:\n","    f.write(output)"]},{"cell_type":"markdown","metadata":{"id":"8VC3IEChUsxP"},"source":["# 上記の単純な機能をLCELで書き直したコード"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"syUa0eLRUsxP"},"outputs":[],"source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","user_input = \"ハッピーエンドのボーイミーツガール\"\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",\"ユーザが指定するジャンル等の情報をもとに、短編小説を生成するAIです。\"),\n","        (\"human\", \"{user_input}\")\n","    ]\n",")\n","\n","output_parser = StrOutputParser()\n","\n","#ここでChainを組む\n","chain = prompt | model | output_parser\n","\n","output = \"\"\n","#テキストが少しずつ生成されるようにするために、streamを使う\n","for chunk in chain.stream({\"user_input\":user_input}):\n","    print(chunk, end=\"\", flush=True)\n","    output += chunk\n","\n","#これまで通りinvokeを利用することもできる\n","#output = chain.invoke({\"user_input\":user_input})\n","\n","with open(\"output_sample02.txt\", \"w\") as f:\n","    f.write(output)"]},{"cell_type":"markdown","metadata":{"id":"Dl2FzaVGUsxQ"},"source":["# プロットを生成してから小説を生成するように機能追加したコード"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xC5jSMt0UsxQ"},"outputs":[],"source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.runnables import (\n","    RunnableLambda,\n","    RunnableParallel,\n","    RunnablePassthrough,\n",")\n","\n","user_input = \"ハッピーエンドのボーイミーツガール\"\n","\n","#CoTのプロンプトを定義\n","cot_system_prompt =  \"\"\"\n","アナタはユーザが指定するジャンル等の情報をもとに、短編小説を生成するための情報を整理するAIです。\n","ユーザが指定したジャンルをもとに、短編小説を生成するための情報をステップバイステップで洗い出してください。\n","\n","まずは、小説を書くうえで決めないといけない内容が何になるのかを、アナタ自身で全て洗い出してください。\n","その後、洗い出した項目を、アナタ自身が決定していってください。\n","\n","ただし、作成する小説は、ユーザが指定したジャンルに沿った内容である必要があります。\n","しかしながら、山あり谷ありの非常に感動するようなストーリーを生成する必要があります。\n","\n","また、使いたい名言や印象的なセリフなども書き出してください。\n","\n","以上をもとに感動的なストーリーを生成するためのプロットをステップバイステップで書き出してください。\n","\"\"\"\n","\n","#小説生成のプロンプトを定義\n","generate_story_system_prompt = \"\"\"\n","アナタは、ユーザが指定するジャンル等の情報をもとに、短編小説を生成するです。\n","ユーザが指定したジャンルに加え、前段でLLMが洗い出した情報をもとに小説を作成してください。\n","\n","前段のLLMが洗い出した情報を小説に入れ込む必要があるため、文字数は長くなっても構いません。\n","むしろ、前段の情報を洗い出していないのにも関わらず、ストーリーの生成を中断してはいけません。\n","\n","またタイトルや段落などは表示しないでください。あくまで小説の本文のみを生成してください。\n","\n","生成する文章はあくまでライトノベルのような内容である必要があります。\n","加えて、あらすじのような書き方は絶対にしてはいけません。\n","地の文で話を進めるのではなく、必ず、詳細な描写と登場人物間の会話でのやり取りをもとに、話を進めるようにしてください。\n","\n","\"\"\"\n","\n","generate_story_human_prompt = \"\"\"\n","# ユーザが指定したジャンル等の情報\n","{user_input}\n","\n","# 前段のLLMが洗い出した情報\n","{information}\n","\"\"\"\n","\n","cot_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",cot_system_prompt),\n","        (\"human\", \"{user_input}\")\n","    ]\n",")\n","\n","generate_story_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",generate_story_system_prompt),\n","        (\"human\", generate_story_human_prompt)\n","    ]\n",")\n","\n","output_parser = StrOutputParser()\n","\n","#CoTを用いて、プロットを生成するChainと、小説を生成するChainを繋げ、各出力を全て次のRunnableに渡す\n","chain = (\n","    RunnableParallel(\n","        {\n","            \"user_input\": RunnablePassthrough(),\n","            \"information\":cot_prompt|model|output_parser,\n","        }\n","    ).assign(novel=generate_story_prompt| model| output_parser)\n",")\n","\n","output = \"\"\n","output_user_input = \"\"\n","output_information = \"\"\n","output_novel = \"\"\n","for chunk in chain.stream({\"user_input\":user_input}):\n","    if \"user_input\" in chunk:\n","        print(chunk[\"user_input\"], end=\"\", flush=True)\n","        output_user_input += chunk[\"user_input\"][\"user_input\"]\n","    elif \"information\" in chunk:\n","        print(chunk[\"information\"],end=\"\", flush=True)\n","        output_information += chunk[\"information\"]\n","    elif \"novel\" in chunk:\n","        print(chunk[\"novel\"], end=\"\", flush=True)\n","        output_novel += chunk[\"novel\"]\n","\n","\n","\n","with open(\"output_sample03.txt\", \"w\") as f:\n","    f.write(\"\\n====user_user_input====\\n\")\n","    f.write(output_user_input)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_information====\\n\")\n","    f.write(output_information)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_novel====\\n\")\n","    f.write(output_novel)\n","    f.write(\"\\n\")"]},{"cell_type":"markdown","metadata":{"id":"vNgMvTqnUsxR"},"source":["# 別のAIエージェントにより改善案を出力してもらい、それを元に改善した小説を生成する機能を追加したコード"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aMqq_CiRUsxR"},"outputs":[],"source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.runnables import (\n","    RunnableLambda,\n","    RunnableParallel,\n","    RunnablePassthrough,\n",")\n","\n","user_input = \"ハッピーエンドのボーイミーツガール\"\n","\n","cot_system_prompt =  \"\"\"\n","アナタはユーザが指定するジャンル等の情報をもとに、短編小説を生成するための情報を整理するAIです。\n","ユーザが指定したジャンルをもとに、短編小説を生成するための情報をステップバイステップで洗い出してください。\n","\n","まずは、小説を書くうえで決めないといけない内容が何になるのかを、アナタ自身で全て洗い出してください。\n","その後、洗い出した項目を、アナタ自身が決定していってください。\n","\n","ただし、作成する小説は、ユーザが指定したジャンルに沿った内容である必要があります。\n","しかしながら、山あり谷ありの非常に感動するようなストーリーを生成する必要があります。\n","\n","また、使いたい名言や印象的なセリフなども書き出してください。\n","\n","以上をもとに感動的なストーリーを生成するためのプロットをステップバイステップで書き出してください。\n","\"\"\"\n","\n","generate_story_system_prompt = \"\"\"\n","アナタは、ユーザが指定するジャンル等の情報をもとに、短編小説を生成するです。\n","ユーザが指定したジャンルに加え、前段でLLMが洗い出した情報をもとに小説を作成してください。\n","\n","前段のLLMが洗い出した情報を小説に入れ込む必要があるため、文字数は長くなっても構いません。\n","むしろ、前段の情報を洗い出していないのにも関わらず、ストーリーの生成を中断してはいけません。\n","\n","またタイトルや段落などは表示しないでください。あくまで小説の本文のみを生成してください。\n","\n","生成する文章はあくまでライトノベルのような内容である必要があります。\n","加えて、あらすじのような書き方は絶対にしてはいけません。\n","地の文で話を進めるのではなく、必ず、詳細な描写と登場人物間の会話でのやり取りをもとに、話を進めるようにしてください。\n","\n","\"\"\"\n","\n","generate_story_human_prompt = \"\"\"\n","# ユーザが指定したジャンル等の情報\n","{user_input}\n","\n","# 前段のLLMが洗い出した情報\n","{information}\n","\"\"\"\n","\n","criticalA_system_prompt = \"\"\"\n","あなたは文芸出版社の編集者になり、私が添付ファイルとして送付する小説を読み、評価をしてください。\n","\n","評価は、項目別の評点と、総合評価、およびコメントによって構成されます。\n","\n","項目別の評点は、「オリジナリティー」「ストーリー」「設定」「キャラクター」「文章力」の5つの観点について、それぞれ良い順に、A、B+、B、B-、Cの5段階での評価をし、それらを踏まえた総合評価でも同様に、A、B+、B、B-、Cの5段階の評価を付けてください。\n","\n","コメントでは、5つの観点の中で特筆すべき良い点と改善点について具体的に述べてください。\n","\n","アナタは、編集者Aとして、小説の良かった点を特に重視して評価をして、最終選考に私の作品を推薦する立場から評価を出力してください。\n","\"\"\"\n","\n","criticalB_system_prompt = \"\"\"\n","あなたは文芸出版社の編集者になり、私が添付ファイルとして送付する小説を読み、評価をしてください。\n","\n","評価は、項目別の評点と、総合評価、およびコメントによって構成されます。\n","\n","項目別の評点は、「オリジナリティー」「ストーリー」「設定」「キャラクター」「文章力」の5つの観点について、それぞれ良い順に、A、B+、B、B-、Cの5段階での評価をし、それらを踏まえた総合評価でも同様に、A、B+、B、B-、Cの5段階の評価を付けてください。\n","\n","コメントでは、5つの観点の中で改善点について具体的に述べてください。\n","\n","アナタは、編集者Bとして、この小説には改善点が大きいという評価をして、厳しい評価をするとともに、最終選考に私の作品を推薦はしないという立場から評価を出力してください。\n","\"\"\"\n","\n","taik_system_prompt = \"\"\"\n","この小説をより良いものにするにはどうすれば良いかを二人の編集者が議論する対話を出力してください。すぐに結論を出さず、議論を様々な角度から深めてください。\n","\"\"\"\n","\n","next_generation_prot_system_prompt = \"\"\"\n","ここまでで、ユーザの指定したジャンルに沿った小説を生成し、編集者に評価をしてもらい、改善点を議論する対話を出力しました。\n","その情報をこれから提示するため、その内容に基づいて、元々の小説を改善するための情報をステップバイステップで洗い出してください。\n","\n","作成する小説は、ユーザが指定したジャンルに沿った内容である必要があります。\n","しかしながら、山あり谷ありの非常に感動するようなストーリーを生成する必要があります。\n","\n","また、使いたい名言や印象的なセリフなども書き出してください。\n","\n","以上をもとに感動的なストーリーを生成するためのプロットをステップバイステップで書き出してください。\n","\n","\"\"\"\n","\n","next_generation_prot_human_prompt = \"\"\"\n","# ユーザが指定したジャンル等の情報\n","{user_input}\n","\n","# 過去に実際に記載した、改善が必要とユーザが判断した小説\n","{novel}\n","\n","# 編集者からの評価\n","{critical_sheet}\n","\n","# 編集者Aと編集者Bの議論\n","{taik}\n","\"\"\"\n","\n","\n","next_generation_novel_system_prompt = \"\"\"\n","ここまでで、ユーザの指定したジャンルに沿った小説を生成し、編集者に評価をしてもらい、改善点を議論する対話を出力しました。\n","その上で、それまでの情報をもとに、改善した内容をLLMに生成してもらいました。\n","\n","改善した内容と、過去の情報をもとに、実際に短編小説を生成してください。\n","\n","前段のLLMが洗い出した情報を小説に入れ込む必要があるため、文字数は長くなっても構いません。\n","むしろ、前段の情報を洗い出していないのにも関わらず、ストーリーの生成を中断してはいけません。\n","\n","生成する文章はあくまでライトノベルのような内容である必要があります。\n","加えて、あらすじのような書き方は絶対にしてはいけません。\n","地の文で話を進めるのではなく、必ず、詳細な描写と登場人物間の会話でのやり取りをもとに、話を進めるようにしてください。\n","\n","山あり谷ありの感動的な話が生成されることを期待しています。アナタならできます。頑張ってください。\n","\"\"\"\n","\n","next_generation_novel_human_prompt = \"\"\"\n","# ユーザが指定したジャンル等の情報\n","{user_input}\n","\n","# 過去に実際に記載した、改善が必要とユーザが判断した小説\n","{novel}\n","\n","# 編集者からの評価\n","{critical_sheet}\n","\n","# 編集者Aと編集者Bの議論\n","{taik}\n","\n","# 上記の内容をもとにLLMが出した改善策\n","{next_novel_plot}\n","\"\"\"\n","\n","\n","\n","\n","\n","cot_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",cot_system_prompt),\n","        (\"human\", \"{user_input}\")\n","    ]\n",")\n","\n","generate_story_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",generate_story_system_prompt),\n","        (\"human\", generate_story_human_prompt)\n","    ]\n",")\n","\n","criticalA_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",criticalA_system_prompt),\n","        (\"human\", \"{novel}\")\n","    ]\n",")\n","\n","criticalB_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",criticalB_system_prompt),\n","        (\"human\", \"{novel}\")\n","    ]\n",")\n","\n","talk_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",taik_system_prompt),\n","        (\"human\", \"{critical_sheet}\")\n","    ]\n",")\n","\n","next_generation_prot_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",next_generation_prot_system_prompt),\n","        (\"human\", next_generation_prot_human_prompt)\n","    ]\n",")\n","\n","next_generation_novel_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",next_generation_novel_system_prompt),\n","        (\"human\", next_generation_novel_human_prompt)\n","    ]\n",")\n","\n","output_parser = StrOutputParser()\n","\n","chain = (\n","    RunnableParallel(\n","        {\n","            \"user_input\": RunnablePassthrough(),\n","            \"information\": cot_prompt | model | output_parser,\n","        }\n","    )\n","    .assign(novel=generate_story_prompt | model | output_parser)\n","    .assign(\n","        critical_sheet = RunnableParallel(\n","            {\n","            \"criticalA_sheet\":criticalA_prompt | model | output_parser,\n","            \"criticalB_sheet\":criticalB_prompt | model | output_parser\n","            }\n","        )\n","    )\n","    .assign(taik=talk_prompt | model | output_parser)\n","    .assign(next_novel_plot=next_generation_prot_prompt | model | output_parser)\n","    .assign(final_novel=next_generation_novel_prompt | model | output_parser)\n",")\n","\n","output = \"\"\n","output_user_input = \"\"\n","output_information = \"\"\n","output_novel = \"\"\n","output_criticalA_sheet = \"\"\n","output_criticalB_sheet = \"\"\n","output_taik = \"\"\n","output_next_novel_plot = \"\"\n","output_final_novel = \"\"\n","\n","for chunk in chain.stream({\"user_input\":user_input}):\n","    if \"user_input\" in chunk:\n","        print(chunk[\"user_input\"], end=\"\", flush=True)\n","        output_user_input += chunk[\"user_input\"][\"user_input\"]\n","    elif \"information\" in chunk:\n","        print(chunk[\"information\"],end=\"\", flush=True)\n","        output_information += chunk[\"information\"]\n","    elif \"novel\" in chunk:\n","        print(chunk[\"novel\"], end=\"\", flush=True)\n","        output_novel += chunk[\"novel\"]\n","    elif \"critical_sheet\" in chunk:\n","        if \"criticalA_sheet\" in chunk[\"critical_sheet\"]:\n","            print(chunk[\"critical_sheet\"][\"criticalA_sheet\"], end=\"\", flush=True)\n","            output_criticalA_sheet += chunk[\"critical_sheet\"][\"criticalA_sheet\"]\n","        elif \"criticalB_sheet\" in chunk[\"critical_sheet\"]:\n","            print(chunk[\"critical_sheet\"][\"criticalB_sheet\"], end=\"\", flush=True)\n","            output_criticalB_sheet += chunk[\"critical_sheet\"][\"criticalB_sheet\"]\n","    elif \"taik\" in chunk:\n","        print(chunk[\"taik\"], end=\"\", flush=True)\n","        output_taik += chunk[\"taik\"]\n","    elif \"next_novel_plot\" in chunk:\n","        print(chunk[\"next_novel_plot\"], end=\"\", flush=True)\n","        output_next_novel_plot += chunk[\"next_novel_plot\"]\n","    elif \"final_novel\" in chunk:\n","        print(chunk[\"final_novel\"], end=\"\", flush=True)\n","        output_final_novel += chunk[\"final_novel\"]\n","\n","\n","\n","\n","with open(\"output_sample04.txt\", \"w\") as f:\n","    f.write(\"\\n====user_user_input====\\n\")\n","    f.write(output_user_input)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_information====\\n\")\n","    f.write(output_information)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_novel====\\n\")\n","    f.write(output_novel)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_critical_sheet====\\n\")\n","    f.write(\"\\n====output_criticalA_sheet====\\n\")\n","    f.write(output_criticalA_sheet)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_criticalB_sheet====\\n\")\n","    f.write(output_criticalB_sheet)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_taik====\\n\")\n","    f.write(output_taik)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_next_novel_plot====\\n\")\n","    f.write(output_next_novel_plot)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_final_novel====\\n\")\n","    f.write(output_final_novel)\n"]},{"cell_type":"markdown","metadata":{"id":"k69zM-F4UsxS"},"source":["# 小説家になろうAPIを利用して、トレンドを取得する機能を追加したコード"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wn0S1aOfUsxS"},"outputs":[],"source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.runnables import (\n","    RunnableLambda,\n","    RunnableParallel,\n","    RunnablePassthrough,\n",")\n","import requests\n","\n","user_input = \"ハッピーエンドのボーイミーツガール\"\n","\n","keyword_extraction_system_prompt = \"\"\"\n","ユーザの入力から、大手小説投稿サイトにて、検索に利用するための重要なキーワード（複数）のみを抽出してください。\n","接続詞や助詞などは除外し、主要な名詞や形容詞だけを含めてください。\n","複数のキーワードがある場合は、必ず半角スペースで区切ってください。カンマなどでは区切らないでください。\n","ただし、抜き出すキーワードは最大3個までにしてください。重要度の高いキーワードから順に抽出してください。\n","\"\"\"\n","\n","cot_system_prompt =  \"\"\"\n","アナタはユーザが指定するジャンル等の情報をもとに、短編小説を生成するための情報を整理するAIです。\n","ユーザが指定したジャンルをもとに、短編小説を生成するための情報をステップバイステップで洗い出してください。\n","\n","まずは、小説を書くうえで決めないといけない内容が何になるのかを、アナタ自身で全て洗い出してください。\n","その後、洗い出した項目を、アナタ自身が決定していってください。\n","\n","ただし、作成する小説は、ユーザが指定したジャンルに沿った内容である必要があります。\n","しかしながら、山あり谷ありの非常に感動するようなストーリーを生成する必要があります。\n","\n","また、使いたい名言や印象的なセリフなども書き出してください。\n","\n","さらに、大規模小説投稿サイトにて高評価を獲得している、関連ジャンルの関連小説情報も参考にしてください。\n","例えば、関連小説情報の大まかなストーリーラインが今流行っている小説の概要です。なので、これから生成する小説もそのストーリーラインに揃えてください。\n","\n","以上をもとに感動的なストーリーを生成するためのプロットをステップバイステップで書き出してください。\n","\"\"\"\n","\n","cot_human_prompt = \"\"\"\n","# ユーザが指定したジャンル等の情報\n","{user_input}\n","\n","# 高評価を得ている取得したジャンルの関連小説情報\n","{naro_novel_info}\n","\"\"\"\n","\n","generate_story_system_prompt = \"\"\"\n","アナタは、ユーザが指定するジャンル等の情報をもとに、短編小説を生成するAIです。\n","ユーザが指定したジャンルに加え、前段でLLMが洗い出した情報をもとに小説を作成してください。\n","\n","前段のLLMが洗い出した情報を小説に入れ込む必要があるため、文字数は長くなっても構いません。\n","むしろ、前段の情報を洗い出していないのにも関わらず、ストーリーの生成を中断してはいけません。\n","\n","またタイトルや段落などは表示しないでください。あくまで小説の本文のみを生成してください。\n","\n","生成する文章はあくまでライトノベルのような内容である必要があります。\n","加えて、あらすじのような書き方は絶対にしてはいけません。\n","地の文で話を進めるのではなく、必ず、詳細な描写と登場人物間の会話でのやり取りをもとに、話を進めるようにしてください。\n","\"\"\"\n","\n","generate_story_human_prompt = \"\"\"\n","# ユーザが指定したジャンル等の情報\n","{user_input}\n","\n","# 前段のLLMが洗い出した情報\n","{information}\n","\"\"\"\n","\n","criticalA_system_prompt = \"\"\"\n","あなたは文芸出版社の編集者になり、私が添付ファイルとして送付する小説を読み、評価をしてください。\n","\n","評価は、項目別の評点と、総合評価、およびコメントによって構成されます。\n","\n","項目別の評点は、「オリジナリティー」「ストーリー」「設定」「キャラクター」「文章力」の5つの観点について、それぞれ良い順に、A、B+、B、B-、Cの5段階での評価をし、それらを踏まえた総合評価でも同様に、A、B+、B、B-、Cの5段階の評価を付けてください。\n","\n","コメントでは、5つの観点の中で特筆すべき良い点と改善点について具体的に述べてください。\n","\n","アナタは、編集者Aとして、小説の良かった点を特に重視して評価をして、最終選考に私の作品を推薦する立場から評価を出力してください。\n","\"\"\"\n","\n","criticalB_system_prompt = \"\"\"\n","あなたは文芸出版社の編集者になり、私が添付ファイルとして送付する小説を読み、評価をしてください。\n","\n","評価は、項目別の評点と、総合評価、およびコメントによって構成されます。\n","\n","項目別の評点は、「オリジナリティー」「ストーリー」「設定」「キャラクター」「文章力」の5つの観点について、それぞれ良い順に、A、B+、B、B-、Cの5段階での評価をし、それらを踏まえた総合評価でも同様に、A、B+、B、B-、Cの5段階の評価を付けてください。\n","\n","コメントでは、5つの観点の中で改善点について具体的に述べてください。\n","\n","アナタは、編集者Bとして、この小説には改善点が大きいという評価をして、厳しい評価をするとともに、最終選考に私の作品を推薦はしないという立場から評価を出力してください。\n","\"\"\"\n","\n","taik_system_prompt = \"\"\"\n","この小説をより良いものにするにはどうすれば良いかを二人の編集者が議論する対話を出力してください。すぐに結論を出さず、議論を様々な角度から深めてください。\n","\"\"\"\n","\n","next_generation_prot_system_prompt = \"\"\"\n","ここまでで、ユーザの指定したジャンルに沿った小説を生成し、編集者に評価をしてもらい、改善点を議論する対話を出力しました。\n","その情報をこれから提示するため、その内容に基づいて、元々の小説を改善するための情報をステップバイステップで洗い出してください。\n","\n","作成する小説は、ユーザが指定したジャンルに沿った内容である必要があります。\n","しかしながら、山あり谷ありの非常に感動するようなストーリーを生成する必要があるため、そのためにどんなストーリーにしたらいいかをステップバイステップで概要を作成してください。\n","\n","また、使いたい名言や印象的なセリフなども書き出してください。\n","\n","\"\"\"\n","\n","next_generation_prot_human_prompt = \"\"\"\n","# ユーザが指定したジャンル等の情報\n","{user_input}\n","\n","# 過去に実際に記載した、改善が必要とユーザが判断した小説\n","{novel}\n","\n","# 編集者からの評価\n","{critical_sheet}\n","\n","# 編集者Aと編集者Bの議論\n","{taik}\n","\"\"\"\n","\n","\n","next_generation_novel_system_prompt = \"\"\"\n","ここまでで、ユーザの指定したジャンルに沿った小説を生成し、編集者に評価をしてもらい、改善点を議論する対話を出力しました。\n","その上で、それまでの情報をもとに、改善した内容をLLMに生成してもらいました。\n","\n","改善した内容と、過去の情報をもとに、実際に短編小説を生成してください。\n","\n","前段のLLMが洗い出した情報を小説に入れ込む必要があるため、文字数は長くなっても構いません。\n","むしろ、前段の情報を洗い出していないのにも関わらず、ストーリーの生成を中断してはいけません。\n","\n","またタイトルや段落などは表示しないでください。あくまで小説の本文のみを生成してください。\n","\n","生成する文章はあくまでライトノベルのような内容である必要があります。\n","加えて、あらすじのような書き方は絶対にしてはいけません。\n","地の文で話を進めるのではなく、必ず、詳細な描写と登場人物間の会話でのやり取りをもとに、話を進めるようにしてください。\n","\n","山あり谷ありの感動的な話が生成されることを期待しています。アナタならできます。頑張ってください。\n","\"\"\"\n","\n","next_generation_novel_human_prompt = \"\"\"\n","# ユーザが指定したジャンル等の情報\n","{user_input}\n","\n","# 過去に実際に記載した、改善が必要とユーザが判断した小説\n","{novel}\n","\n","# 編集者からの評価\n","{critical_sheet}\n","\n","# 編集者Aと編集者Bの議論\n","{taik}\n","\n","# 上記の内容をもとにLLMが出した改善策\n","{next_novel_plot}\n","\"\"\"\n","\n","\n","# LangChainでキーワード抽出用プロンプトの設定\n","keyword_extraction_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", keyword_extraction_system_prompt),\n","        (\"human\", \"{user_input}\")\n","    ]\n",")\n","\n","\n","cot_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",cot_system_prompt),\n","        (\"human\", cot_human_prompt)\n","    ]\n",")\n","\n","generate_story_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",generate_story_system_prompt),\n","        (\"human\", generate_story_human_prompt)\n","    ]\n",")\n","\n","criticalA_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",criticalA_system_prompt),\n","        (\"human\", \"{novel}\")\n","    ]\n",")\n","\n","criticalB_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",criticalB_system_prompt),\n","        (\"human\", \"{novel}\")\n","    ]\n",")\n","\n","talk_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",taik_system_prompt),\n","        (\"human\", \"{critical_sheet}\")\n","    ]\n",")\n","\n","next_generation_prot_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",next_generation_prot_system_prompt),\n","        (\"human\", next_generation_prot_human_prompt)\n","    ]\n",")\n","\n","next_generation_novel_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",next_generation_novel_system_prompt),\n","        (\"human\", next_generation_novel_human_prompt)\n","    ]\n",")\n","\n","output_parser = StrOutputParser()\n","\n","# なろうAPIを使って、ジャンルに基づいた評価の高い小説情報を取得する関数\n","def fetch_narou_novel_info(user_keyword):\n","    url = \"https://api.syosetu.com/novelapi/api/\"\n","    params = {\n","        \"word\": user_keyword,\n","        \"order\": \"monthlypoint\",\n","        \"out\": \"json\",\n","        \"lim\": 10\n","    }\n","\n","    response = requests.get(url, params=params)\n","\n","    if response.status_code == 200:\n","        novels = response.json()[1:]\n","        return [{\"title\": novel.get(\"title\", \"\"),\n","                 \"summary\": novel.get(\"story\", \"\"),\n","                 \"tag\": novel.get(\"keyword\", \"\").split()}\n","                for novel in novels]\n","    else:\n","        return [\"検索した結果、関連小説情報を取得できませんでした。\"]\n","\n","chain = (\n","    RunnableParallel(\n","        {\n","            \"user_input\": RunnablePassthrough(),\n","            \"search_words\": keyword_extraction_prompt | model | output_parser,\n","        }\n","    )\n","    .assign(naro_novel_info=RunnableLambda(lambda inputs: {\"naro_novel_info\": fetch_narou_novel_info(inputs[\"search_words\"])}))\n","    .assign(\n","        cot_prompt_output=RunnableLambda(lambda inputs: {\n","            \"cot_prompt_output\": cot_prompt.invoke({\"user_input\": inputs[\"user_input\"], \"naro_novel_info\": inputs[\"naro_novel_info\"]})\n","        })\n","    )\n","    .assign(information=cot_prompt | model | output_parser)\n","    .assign(novel=generate_story_prompt | model | output_parser)\n","    .assign(\n","        critical_sheet = RunnableParallel(\n","            {\n","            \"criticalA_sheet\":criticalA_prompt | model | output_parser,\n","            \"criticalB_sheet\":criticalB_prompt | model | output_parser\n","            }\n","        )\n","    )\n","    .assign(taik=talk_prompt | model | output_parser)\n","    .assign(next_novel_plot=next_generation_prot_prompt | model | output_parser)\n","    .assign(final_novel=next_generation_novel_prompt | model | output_parser)\n",")\n","\n","output = \"\"\n","output_user_input = \"\"\n","output_information = \"\"\n","output_novel = \"\"\n","output_criticalA_sheet = \"\"\n","output_criticalB_sheet = \"\"\n","output_taik = \"\"\n","output_next_novel_plot = \"\"\n","output_final_novel = \"\"\n","output_naro_novel_info = \"\"\n","output_search_words = \"\"\n","output_cot_prompt_output = \"\"\n","\n","for chunk in chain.stream({\"user_input\":user_input}):\n","    if \"user_input\" in chunk:\n","        print(chunk[\"user_input\"][\"user_input\"], end=\"\", flush=True)\n","        output_user_input += chunk[\"user_input\"][\"user_input\"]\n","    elif \"search_words\" in chunk:\n","        print(chunk[\"search_words\"], end=\"\", flush=True)\n","        output_search_words += chunk[\"search_words\"]\n","    elif \"naro_novel_info\" in chunk:\n","        print(chunk[\"naro_novel_info\"], end=\"\", flush=True)\n","        output_naro_novel_info += str(chunk[\"naro_novel_info\"])\n","    elif \"cot_prompt_output\" in chunk:\n","        if \"cot_prompt_output\" in chunk:\n","            print(chunk[\"cot_prompt_output\"][\"cot_prompt_output\"], end=\"\", flush=True)\n","            output_cot_prompt_output += str(chunk[\"cot_prompt_output\"][\"cot_prompt_output\"])\n","    elif \"information\" in chunk:\n","        print(chunk[\"information\"],end=\"\", flush=True)\n","        output_information += chunk[\"information\"]\n","    elif \"novel\" in chunk:\n","        print(chunk[\"novel\"], end=\"\", flush=True)\n","        output_novel += chunk[\"novel\"]\n","    elif \"critical_sheet\" in chunk:\n","        if \"criticalA_sheet\" in chunk[\"critical_sheet\"]:\n","            print(chunk[\"critical_sheet\"][\"criticalA_sheet\"], end=\"\", flush=True)\n","            output_criticalA_sheet += chunk[\"critical_sheet\"][\"criticalA_sheet\"]\n","        elif \"criticalB_sheet\" in chunk[\"critical_sheet\"]:\n","            print(chunk[\"critical_sheet\"][\"criticalB_sheet\"], end=\"\", flush=True)\n","            output_criticalB_sheet += chunk[\"critical_sheet\"][\"criticalB_sheet\"]\n","    elif \"taik\" in chunk:\n","        print(chunk[\"taik\"], end=\"\", flush=True)\n","        output_taik += chunk[\"taik\"]\n","    elif \"next_novel_plot\" in chunk:\n","        print(chunk[\"next_novel_plot\"], end=\"\", flush=True)\n","        output_next_novel_plot += chunk[\"next_novel_plot\"]\n","    elif \"final_novel\" in chunk:\n","        print(chunk[\"final_novel\"], end=\"\", flush=True)\n","        output_final_novel += chunk[\"final_novel\"]\n","\n","\n","\n","\n","with open(\"output_sample05.txt\", \"w\") as f:\n","    f.write(\"\\n====user_user_input====\\n\")\n","    f.write(output_user_input)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_search_words====\\n\")\n","    f.write(output_search_words)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_naro_novel_info====\\n\")\n","    f.write(output_naro_novel_info)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_cot_prompt_output====\\n\")\n","    f.write(output_cot_prompt_output)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_information====\\n\")\n","    f.write(output_information)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_novel====\\n\")\n","    f.write(output_novel)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_critical_sheet====\\n\")\n","    f.write(\"\\n====output_criticalA_sheet====\\n\")\n","    f.write(output_criticalA_sheet)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_criticalB_sheet====\\n\")\n","    f.write(output_criticalB_sheet)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_taik====\\n\")\n","    f.write(output_taik)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_next_novel_plot====\\n\")\n","    f.write(output_next_novel_plot)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_final_novel====\\n\")\n","    f.write(output_final_novel)\n"]},{"cell_type":"markdown","metadata":{"id":"t-WJsPAuEWzM"},"source":["# より長編の小説を生成できるようにチャプターごとに小説を生成する機能を追加したコード\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JKldlm7lUsxT"},"outputs":[],"source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","from langchain_core.runnables import (\n","    RunnableLambda,\n","    RunnableParallel,\n","    RunnablePassthrough,\n",")\n","import requests\n","\n","user_input = \"ハッピーエンドのボーイミーツガール\"\n","all_chapter_number = 4\n","\n","keyword_extraction_system_prompt = \"\"\"\n","ユーザの入力から、大手小説投稿サイトにて、検索に利用するための重要なキーワード（複数）のみを抽出してください。\n","接続詞や助詞などは除外し、主要な名詞や形容詞だけを含めてください。\n","複数のキーワードがある場合は、必ず半角スペースで区切ってください。カンマなどでは区切らないでください。\n","ただし、抜き出すキーワードは最大3個までにしてください。重要度の高いキーワードから順に抽出してください。\n","\"\"\"\n","\n","cot_system_prompt =  \"\"\"\n","アナタはユーザが指定するジャンル等の情報をもとに、短編小説を生成するための情報を整理するAIです。\n","ユーザが指定したジャンルをもとに、長編小説を生成するための情報をステップバイステップで洗い出してください。\n","\n","まずは、小説を書くうえで決めないといけない内容が何になるのかを、アナタ自身で全て洗い出してください。\n","その後、洗い出した項目を、アナタ自身が決定していってください。\n","\n","ただし、作成する小説は、ユーザが指定したジャンルに沿った内容である必要があります。\n","しかしながら、山あり谷ありの非常に感動するようなストーリーを生成する必要があります。\n","\n","また、使いたい名言や印象的なセリフなども書き出してください。\n","\n","さらに、大規模小説投稿サイトにて高評価を獲得している、関連ジャンルの関連小説情報も参考にしてください。\n","例えば、関連小説情報の大まかなストーリーラインが今流行っている小説の概要です。なので、これから生成する小説もそのストーリーラインに揃えてください。\n","\n","また、今回記載してもらう小説は、全{all_chapter_number}章により構成される小説です。\n","最後に、各章ごとにどんなストーリーにするかを、ユーザが指定したジャンルや、関連小説情報の概要をもとに、ステップバイステップで記載してください。\n","\n","以上をもとに感動的なストーリーを生成するためのプロットをステップバイステップで書き出してください。\n","\"\"\"\n","\n","cot_human_prompt = \"\"\"\n","# ユーザが指定したジャンル等の情報\n","{user_input}\n","\n","# 高評価を得ている取得したジャンルの関連小説情報\n","{naro_novel_info}\n","\"\"\"\n","\n","generate_story_system_prompt = \"\"\"\n","アナタは、ユーザが指定するジャンル等の情報をもとに、長編小説を生成するAIです。\n","ユーザが指定したジャンルに加え、前段でLLMが洗い出した情報をもとに小説を作成してください。\n","\n","前段のLLMが洗い出した情報を小説に入れ込む必要があるため、文字数は長くなっても構いません。\n","むしろ、前段の情報を洗い出していないのにも関わらず、ストーリーの生成を中断してはいけません。\n","\n","またタイトルや段落などは表示しないでください。あくまで小説の本文のみを生成してください。\n","また、今回記載してもらう小説は、全{all_chapter_number}章により構成される小説です。指定された章の小説を記載してください。\n","\n","生成する文章はあくまでライトノベルのような内容である必要があります。\n","加えて、あらすじのような書き方は絶対にしてはいけません。\n","地の文で話を進めるのではなく、必ず、詳細な描写と登場人物間の会話でのやり取りをもとに、話を進めるようにしてください。\n","\"\"\"\n","\n","generate_story_human_prompt = \"\"\"\n","\n","# 前段のLLMが考えた、今回書く小説のプロット情報\n","{information}\n","\n","# 本小説の全話数\n","{all_chapter_number}\n","\n","# 今回書いて欲しい話数\n","{chapter}\n","\n","# 前話までの小説本文\n","{prev_novel}\n","\n","----\n","\n","この続きから記載してください\n","\n","----\n","\n","\n","\"\"\"\n","\n","criticalA_system_prompt = \"\"\"\n","あなたは文芸出版社の編集者になり、私が添付ファイルとして送付する小説を読み、評価をしてください。\n","\n","評価は、項目別の評点と、総合評価、およびコメントによって構成されます。\n","\n","項目別の評点は、「オリジナリティー」「ストーリー」「設定」「キャラクター」「文章力」の5つの観点について、それぞれ良い順に、A、B+、B、B-、Cの5段階での評価をし、それらを踏まえた総合評価でも同様に、A、B+、B、B-、Cの5段階の評価を付けてください。\n","\n","コメントでは、5つの観点の中で特筆すべき良い点と改善点について具体的に述べてください。\n","\n","アナタは、編集者Aとして、小説の良かった点を特に重視して評価をして、最終選考に私の作品を推薦する立場から評価を出力してください。\n","\"\"\"\n","\n","criticalB_system_prompt = \"\"\"\n","あなたは文芸出版社の編集者になり、私が添付ファイルとして送付する小説を読み、評価をしてください。\n","\n","評価は、項目別の評点と、総合評価、およびコメントによって構成されます。\n","\n","項目別の評点は、「オリジナリティー」「ストーリー」「設定」「キャラクター」「文章力」の5つの観点について、それぞれ良い順に、A、B+、B、B-、Cの5段階での評価をし、それらを踏まえた総合評価でも同様に、A、B+、B、B-、Cの5段階の評価を付けてください。\n","\n","コメントでは、5つの観点の中で改善点について具体的に述べてください。\n","\n","アナタは、編集者Bとして、この小説には改善点が大きいという評価をして、厳しい評価をするとともに、最終選考に私の作品を推薦はしないという立場から評価を出力してください。\n","\"\"\"\n","\n","taik_system_prompt = \"\"\"\n","この小説をより良いものにするにはどうすれば良いかを二人の編集者が議論する対話を出力してください。すぐに結論を出さず、議論を様々な角度から深めてください。\n","\"\"\"\n","\n","next_generation_prot_system_prompt = \"\"\"\n","ここまでで、ユーザの指定したジャンルに沿った小説を生成し、編集者に評価をしてもらい、改善点を議論する対話を出力しました。\n","その情報をこれから提示するため、その内容に基づいて、元々の小説を改善するための情報をステップバイステップで洗い出してください。\n","\n","作成する小説は、ユーザが指定したジャンルに沿った内容である必要があります。\n","しかしながら、山あり谷ありの非常に感動するようなストーリーを生成する必要があります。\n","\n","また、使いたい名言や印象的なセリフなども書き出してください。\n","\n","また、今回記載してもらう小説は、全{all_chapter_number}章により構成される小説です。\n","最後に、各章ごとにどんなストーリーにするかを、ステップバイステップで記載してください。\n","\n","以上をもとに感動的なストーリーを生成するためのプロットをステップバイステップで書き出してください。\n","\n","\"\"\"\n","\n","next_generation_prot_human_prompt = \"\"\"\n","# ユーザが指定したジャンル等の情報\n","{user_input}\n","\n","# 過去に実際に記載した、改善が必要とユーザが判断した小説\n","{novel}\n","\n","# 編集者からの評価\n","{critical_sheet}\n","\n","# 編集者Aと編集者Bの議論\n","{taik}\n","\"\"\"\n","\n","\n","next_generation_novel_system_prompt = \"\"\"\n","ここまでで、ユーザの指定したジャンルに沿った小説を生成し、編集者に評価をしてもらい、改善点を議論する対話を出力しました。\n","その上で、それまでの情報をもとに、改善した内容をLLMに生成してもらいました。\n","\n","改善した内容と、過去の情報をもとに、実際に長編小説を生成してください。\n","\n","前段のLLMが洗い出した情報を小説に入れ込む必要があるため、文字数は長くなっても構いません。\n","むしろ、前段の情報を洗い出していないのにも関わらず、ストーリーの生成を中断してはいけません。\n","\n","またタイトルや段落などは表示しないでください。あくまで小説の本文のみを生成してください。\n","また、今回記載してもらう小説は、全{all_chapter_number}章により構成される小説です。指定された章の小説を記載してください。\n","\n","生成する文章はあくまでライトノベルのような内容である必要があります。\n","加えて、あらすじのような書き方は絶対にしてはいけません。\n","地の文で話を進めるのではなく、必ず、詳細な描写と登場人物間の会話でのやり取りをもとに、話を進めるようにしてください。\n","\n","山あり谷ありの感動的な話が生成されることを期待しています。アナタならできます。頑張ってください。\n","\"\"\"\n","\n","next_generation_novel_human_prompt = \"\"\"\n","# 過去に実際に記載した、改善が必要とユーザが判断した小説\n","{novel}\n","\n","# 編集者からの評価\n","{critical_sheet}\n","\n","# 編集者Aと編集者Bの議論\n","{taik}\n","\n","# 上記の内容をもとにLLMが出した改善策\n","{next_novel_plot}\n","\n","# 本小説の全話数\n","{all_chapter_number}\n","\n","# 今回書いて欲しい話数\n","{chapter}\n","\n","# 前話までの小説本文\n","{prev_novel}\n","\n","----\n","\n","この続きから記載してください\n","\n","----\n","\"\"\"\n","\n","\n","# LangChainでキーワード抽出用プロンプトの設定\n","keyword_extraction_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\", keyword_extraction_system_prompt),\n","        (\"human\", \"{user_input}\")\n","    ]\n",")\n","\n","\n","cot_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",cot_system_prompt),\n","        (\"human\", cot_human_prompt)\n","    ]\n",")\n","\n","generate_story_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",generate_story_system_prompt),\n","        (\"human\", generate_story_human_prompt)\n","    ]\n",")\n","\n","criticalA_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",criticalA_system_prompt),\n","        (\"human\", \"{novel}\")\n","    ]\n",")\n","\n","criticalB_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",criticalB_system_prompt),\n","        (\"human\", \"{novel}\")\n","    ]\n",")\n","\n","talk_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",taik_system_prompt),\n","        (\"human\", \"{critical_sheet}\")\n","    ]\n",")\n","\n","next_generation_prot_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",next_generation_prot_system_prompt),\n","        (\"human\", next_generation_prot_human_prompt)\n","    ]\n",")\n","\n","next_generation_novel_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"system\",next_generation_novel_system_prompt),\n","        (\"human\", next_generation_novel_human_prompt)\n","    ]\n",")\n","\n","output_parser = StrOutputParser()\n","\n","# なろうAPIを使って、ジャンルに基づいた評価の高い小説情報を取得する関数\n","def fetch_narou_novel_info(user_keyword):\n","    url = \"https://api.syosetu.com/novelapi/api/\"\n","    params = {\n","        \"word\": user_keyword,\n","        \"order\": \"monthlypoint\",\n","        \"out\": \"json\",\n","        \"lim\": 10\n","    }\n","\n","    response = requests.get(url, params=params)\n","\n","    if response.status_code == 200:\n","        novels = response.json()[1:]\n","        return [{\"title\": novel.get(\"title\", \"\"),\n","                 \"summary\": novel.get(\"story\", \"\"),\n","                 \"tag\": novel.get(\"keyword\", \"\").split()}\n","                for novel in novels]\n","    else:\n","        return [\"検索した結果、関連小説情報を取得できませんでした。\"]\n","\n","\n","def generate_novel_by_chapters(user_input, initial_novel_info, prompt):\n","    final_novel_output = \"\"\n","    past_content = \"\"\n","    chapter_num = 1\n","\n","    while chapter_num <= all_chapter_number:\n","\n","        chapter_input = {\n","            \"all_chapter_number\": all_chapter_number,\n","            \"user_input\": user_input,\n","            \"prev_novel\": past_content,\n","            \"chapter\": chapter_num,\n","            \"information\": initial_novel_info\n","        }\n","\n","        sub_chain = prompt| model | output_parser\n","        current_chapter_output = sub_chain.invoke(chapter_input)\n","\n","        final_novel_output += f\"\\n==== Chapter {chapter_num} ====\\n\" + current_chapter_output\n","        past_content += current_chapter_output\n","\n","        chapter_num += 1\n","\n","    return final_novel_output\n","\n","def generate_final_novel_by_chapters(user_input, novel, critical_sheet, taik, next_novel_plot, prompt):\n","    final_novel_output = \"\"\n","    past_content = \"\"\n","    chapter_num = 1\n","\n","    while chapter_num <= all_chapter_number:\n","        chapter_input = {\n","            \"all_chapter_number\": all_chapter_number,\n","            \"user_input\": user_input,\n","            \"novel\": novel,\n","            \"critical_sheet\": critical_sheet,\n","            \"taik\": taik,\n","            \"next_novel_plot\": next_novel_plot,\n","            \"prev_novel\": past_content,\n","            \"chapter\": chapter_num,\n","        }\n","\n","        sub_chain = prompt| model | output_parser\n","\n","        current_chapter_output = sub_chain.invoke(chapter_input)\n","\n","        final_novel_output += f\"\\n==== Chapter {chapter_num} ====\\n\" + current_chapter_output\n","        past_content += current_chapter_output\n","\n","        chapter_num += 1\n","\n","    return final_novel_output\n","\n","chain = (\n","    RunnableParallel(\n","        {\n","            \"user_input\": RunnablePassthrough(),\n","            \"all_chapter_number\": RunnablePassthrough(),\n","            \"search_words\": keyword_extraction_prompt | model | output_parser,\n","        }\n","    )\n","    .assign(naro_novel_info=RunnableLambda(lambda inputs: {\"naro_novel_info\": fetch_narou_novel_info(inputs[\"search_words\"])}))\n","    .assign(\n","        cot_prompt_output=RunnableLambda(lambda inputs: {\n","            \"cot_prompt_output\": cot_prompt.invoke({\"all_chapter_number\":inputs[\"all_chapter_number\"],\"user_input\": inputs[\"user_input\"], \"naro_novel_info\": inputs[\"naro_novel_info\"]})\n","        })\n","    )\n","    .assign(information=cot_prompt | model | output_parser)\n","    .assign(novel=RunnableLambda(lambda inputs: {\n","        \"novel\": generate_novel_by_chapters(inputs[\"user_input\"], inputs[\"information\"], generate_story_prompt)\n","    }))\n","    .assign(\n","        critical_sheet = RunnableParallel(\n","            {\n","            \"criticalA_sheet\":criticalA_prompt | model | output_parser,\n","            \"criticalB_sheet\":criticalB_prompt | model | output_parser\n","            }\n","        )\n","    )\n","    .assign(taik=talk_prompt | model | output_parser)\n","    .assign(next_novel_plot=next_generation_prot_prompt | model | output_parser)\n","    .assign(final_novel=RunnableLambda(lambda inputs: {\n","        \"final_novel\": generate_final_novel_by_chapters(\n","            inputs[\"user_input\"],\n","            inputs[\"novel\"],\n","            inputs[\"critical_sheet\"],\n","            inputs[\"taik\"],\n","            inputs[\"next_novel_plot\"],\n","            next_generation_novel_prompt)\n","    }))\n",")\n","\n","output = \"\"\n","output_user_input = \"\"\n","output_information = \"\"\n","output_novel = \"\"\n","output_criticalA_sheet = \"\"\n","output_criticalB_sheet = \"\"\n","output_taik = \"\"\n","output_next_novel_plot = \"\"\n","output_final_novel = \"\"\n","output_naro_novel_info = \"\"\n","output_search_words = \"\"\n","output_cot_prompt_output = \"\"\n","\n","for chunk in chain.stream({\"user_input\":user_input, \"all_chapter_number\": str(all_chapter_number)}):\n","    if \"user_input\" in chunk:\n","        print(chunk[\"user_input\"][\"user_input\"], end=\"\", flush=True)\n","        output_user_input += chunk[\"user_input\"][\"user_input\"]\n","    elif \"search_words\" in chunk:\n","        print(chunk[\"search_words\"], end=\"\", flush=True)\n","        output_search_words += chunk[\"search_words\"]\n","    elif \"naro_novel_info\" in chunk:\n","        print(chunk[\"naro_novel_info\"], end=\"\", flush=True)\n","        output_naro_novel_info += str(chunk[\"naro_novel_info\"])\n","    elif \"cot_prompt_output\" in chunk:\n","        if \"cot_prompt_output\" in chunk[\"cot_prompt_output\"]:\n","            print(chunk[\"cot_prompt_output\"][\"cot_prompt_output\"], end=\"\", flush=True)\n","            output_cot_prompt_output += str(chunk[\"cot_prompt_output\"][\"cot_prompt_output\"])\n","    elif \"information\" in chunk:\n","        print(chunk[\"information\"],end=\"\", flush=True)\n","        output_information += chunk[\"information\"]\n","    elif \"novel\" in chunk:\n","        if \"novel\" in chunk[\"novel\"]:\n","            print(chunk[\"novel\"][\"novel\"], end=\"\", flush=True)\n","            output_novel += chunk[\"novel\"][\"novel\"]\n","    elif \"critical_sheet\" in chunk:\n","        if \"criticalA_sheet\" in chunk[\"critical_sheet\"]:\n","            print(chunk[\"critical_sheet\"][\"criticalA_sheet\"], end=\"\", flush=True)\n","            output_criticalA_sheet += chunk[\"critical_sheet\"][\"criticalA_sheet\"]\n","        elif \"criticalB_sheet\" in chunk[\"critical_sheet\"]:\n","            print(chunk[\"critical_sheet\"][\"criticalB_sheet\"], end=\"\", flush=True)\n","            output_criticalB_sheet += chunk[\"critical_sheet\"][\"criticalB_sheet\"]\n","    elif \"taik\" in chunk:\n","        print(chunk[\"taik\"], end=\"\", flush=True)\n","        output_taik += chunk[\"taik\"]\n","    elif \"next_novel_plot\" in chunk:\n","        print(chunk[\"next_novel_plot\"], end=\"\", flush=True)\n","        output_next_novel_plot += chunk[\"next_novel_plot\"]\n","    elif \"final_novel\" in chunk:\n","        if \"final_novel\" in chunk[\"final_novel\"]:\n","            print(chunk[\"final_novel\"][\"final_novel\"], end=\"\", flush=True)\n","            output_final_novel += chunk[\"final_novel\"][\"final_novel\"]\n","\n","\n","with open(\"output_sample06.txt\", \"w\") as f:\n","    f.write(\"\\n====user_user_input====\\n\")\n","    f.write(output_user_input)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_search_words====\\n\")\n","    f.write(output_search_words)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_naro_novel_info====\\n\")\n","    f.write(output_naro_novel_info)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_cot_prompt_output====\\n\")\n","    f.write(output_cot_prompt_output)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_information====\\n\")\n","    f.write(output_information)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_novel====\\n\")\n","    f.write(output_novel)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_critical_sheet====\\n\")\n","    f.write(\"\\n====output_criticalA_sheet====\\n\")\n","    f.write(output_criticalA_sheet)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_criticalB_sheet====\\n\")\n","    f.write(output_criticalB_sheet)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_taik====\\n\")\n","    f.write(output_taik)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_next_novel_plot====\\n\")\n","    f.write(output_next_novel_plot)\n","    f.write(\"\\n\")\n","    f.write(\"\\n====output_final_novel====\\n\")\n","    f.write(output_final_novel)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1731666748383,"user":{"displayName":"akc kug","userId":"06740133965745108662"},"user_tz":-540},"id":"5FIP_TZFUsxU"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
